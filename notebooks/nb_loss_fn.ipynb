{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cross Entropy Loss manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: tensor([[0.3000, 0.2000, 0.4000, 0.1000],\n",
      "        [0.4000, 0.1000, 0.3000, 0.2000],\n",
      "        [0.3000, 0.5000, 0.1000, 0.2000]]) \n",
      "\n",
      "target: tensor([2, 0, 1]) \n",
      "\n",
      "proba_sofmax: tensor([[0.2612, 0.2363, 0.2887, 0.2138],\n",
      "        [0.2887, 0.2138, 0.2612, 0.2363],\n",
      "        [0.2535, 0.3096, 0.2075, 0.2294]])\n",
      "\n",
      "selected_proba: tensor([0.2887, 0.2887, 0.3096])\n",
      "\n",
      "manual_cross_entropy_loss: 1.2191709280014038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Suppose we have prediction\n",
    "prediction = torch.tensor([[0.3, 0.2, 0.4, 0.1], [0.4, 0.1, 0.3, 0.2], [0.3, 0.5, 0.1, 0.2]])\n",
    "\n",
    "# Suppose we have target indexes\n",
    "target = torch.tensor([2, 0, 1])\n",
    "\n",
    "# Apply softmax to the prediction to get probabilities\n",
    "proba_sofmax = F.softmax(prediction, dim=1)\n",
    "\n",
    "# Select the probabilities corresponding to the true classes\n",
    "selected_proba = proba_sofmax[range(len(target)), target]\n",
    "\n",
    "# Compute the negative log likelihood loss\n",
    "manual_cross_entropy_loss = -torch.log(selected_proba).mean()\n",
    "\n",
    "# Print out results\n",
    "print(\"prediction: {} \\n\".format(prediction))\n",
    "print(\"target: {} \\n\".format(target))\n",
    "print(\"proba_sofmax: {}\\n\".format(proba_sofmax))\n",
    "print(\"selected_proba: {}\\n\".format(selected_proba))\n",
    "print(\"manual_cross_entropy_loss: {}\\n\".format(manual_cross_entropy_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cross Entropy Loss by nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: tensor([[0.3000, 0.2000, 0.4000, 0.1000],\n",
      "        [0.4000, 0.1000, 0.3000, 0.2000],\n",
      "        [0.3000, 0.5000, 0.1000, 0.2000]]) \n",
      "\n",
      "target: tensor([2, 0, 1]) \n",
      "\n",
      "cross_entropy_loss: 1.2191709280014038 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Suppose we have prediction\n",
    "prediction = torch.tensor([[0.3, 0.2, 0.4, 0.1], [0.4, 0.1, 0.3, 0.2], [0.3, 0.5, 0.1, 0.2]])\n",
    "\n",
    "# Suppose we have target indexes\n",
    "target = torch.tensor([2, 0, 1])\n",
    "\n",
    "# Compute the cross entropy loss\n",
    "loss = loss_fn(prediction, target)\n",
    "\n",
    "# Print out results\n",
    "print(\"prediction: {} \\n\".format(prediction))\n",
    "print(\"target: {} \\n\".format(target))\n",
    "print(\"cross_entropy_loss: {} \\n\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "part3-trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
